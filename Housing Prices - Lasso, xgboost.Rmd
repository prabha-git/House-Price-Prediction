
output: html_document
---

Inspired by this kernel https://www.kaggle.com/erikbruin/house-prices-lasso-xgboost-and-a-detailed-eda

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r load_lib, message=FALSE, warning=TRUE}
library(tidyverse)
library(tidyimpute)
library(corrplot)
library(caret)
library(xgboost)
library(scales)
library(gridExtra)
library(grid)
library(corrplot)
library(psych)
library(randomForest)
```


Below , i am reading the train / test csv as dataframes in R

```{r load_data, message=FALSE, warning=FALSE}
train=read_csv("datasets/train.csv")
test=read_csv("datasets/test.csv")
```

Getting the dimensions of the dataset , and looks like difference between train and test is "SalePrice" as expected

```{r}
dim(train)
dim(test)
setdiff(colnames(train),colnames(test))
```

Getting rid of IDs from the dataframe , but we need to keep test_ids fro final submission to kaggle
```{r}
test_id=test$Id
test$Id=NULL
train$Id=NULL
```

combining both train and test for cleaning and feature engineering and rename columns with number

```{r}
test$SalePrice=NA
all=rbind(train,test)
all=all %>% mutate(row_name=row_number())


all=all %>% rename(`X1stFlrSF`=`1stFlrSF`,`X2ndFlrSF`=`2ndFlrSF`,`X3SsnPorch`=`3SsnPorch`)
dim(all)
```

Exploring teh important variables

1. Response Variable - SalePrice

the sale price are right skewed. We need to handle this scenario before modeling.
```{r}
all %>% drop_na(SalePrice) %>% ggplot(aes(x=SalePrice))+geom_histogram(fill="blue",binwidth=10000)
```


```{r}
summary(all$SalePrice)
```


Find the most important numeric predictors

first focus on numeric predictors, there are 37 numeric columns including SalePrice

```{r}
all %>% select_if(is.numeric) %>% dim()
all_numVar=all %>% select_if(is.numeric) 
cor_numVar=cor(all_numVar,use="pairwise.complete.obs")
```


```{r}
cor_sorted=as.matrix(sort(cor_numVar[,'SalePrice'],decreasing = TRUE))
high_corr=names(cor_sorted[cor_sorted>0.5,])
corr_numVar=cor_numVar[high_corr,high_corr]
corrplot.mixed(corr_numVar,tl.pos="lt",tl.col="black")
```


lets explore 'overallqual' variable, there is definitively positive influence on the SalePrice

```{r}
all %>% drop_na(SalePrice) %>% ggplot(aes(x=as.factor(OverallQual),y=SalePrice))+geom_boxplot(col="blue")
```



Next 'GrLvArea' variable, there are two outliers with hign GrLivArea but low SalePrice
```{r}
all %>% drop_na(SalePrice) %>%ggplot(aes(x=GrLivArea,y=SalePrice))+geom_point(col='blue')+geom_smooth(method='lm',se=FALSE,col='black')
```


Handling missing data, label  encoding & factorizing variables
find out the variables containing missing values, we have to fix 34 predictors

```{r}
NA_col=names(which(colSums(is.na(all))>0))
sort(sort(colSums(is.na(all[,NA_col]))),decreasing = TRUE)
cat('There are ',length(NA_col),' columsn with missing values')
```


Imputing missing data

## {.tabset}

### Pool
The PoolQC is the variable with most NAs. 
PoolQC : Pool quality

Ex Excellent
Gd Good
TA Average/Typical
Fa Fair
NA No Pool

It is obvious most houses will not have pools . these values can be converted as ordinal
```{r}
all$PoolQC[is.na(all$PoolQC)]='None'
all$PoolQC=as.integer(recode(all$PoolQC,'None'=0,'po'=1,'Fa'=2,'TA'=3,'Gd'=4,'Ex'=5))
```

There are three instances where PoolQC is missing while PoolArea is greater than zero. Iam going to impoute based on overall quality
```{r}
all %>% filter(PoolArea>0 & PoolQC==0) %>% select(PoolArea,PoolQC,OverallQual)
all[all$PoolArea==368 & all$OverallQual==4,]['PoolQC']=2
all[all$PoolArea==444 & all$OverallQual==6,]['PoolQC']=3
all[all$PoolArea==561 & all$OverallQual==3,]['PoolQC']=2
```



### Miscellaneous Feature
There are 2814 missing values in 'MiscFeature, As these values are nor ordinal i will convert into factors
Gar2 2nd Garage (if not described in garage section)
Othr Other
Shed Shed (over 100 Sf)
TenC Tennis Court
NA None

```{r}
table(all$MiscFeature,exclude = NULL)
all=all %>%  replace_na(list(MiscFeature="None"))
all$MiscFeature=as.factor(all$MiscFeature)
all %>% drop_na(SalePrice) %>% ggplot(aes(x=MiscFeature,y=SalePrice))+geom_bar(stat='summary',fun.y="median",fill='blue')+geom_label(stat="count",aes(label=..count..,y=..count..))
```


### Alley

Convert values to factors as it is not ordinal
```{r}
table(all$Alley,exclude = NULL)
```

Grvl Gravel
Pave Paved
NA no alley access

```{r}
all=all %>% replace_na(list(Alley="None"))
all$Alley=as.factor(all$Alley)
```


### Fence

Fence has 2348 missing values, 

```{r}
table(all$Fence,exclude = NULL)
all=all %>% replace_na(list(Fence="None"))
table(all$Fence,exclude=NULL)
all %>% drop_na(SalePrice) %>% group_by(Fence) %>% summarise(median=median(SalePrice),mean=mean(SalePrice),count=n())
```

at the first look Fence looks like an ordinal value but median value shown no fence house has higher median and mean prices , hence i will convert fence as factor
```{r}
all$Fence=as.factor(all$Fence)
```

### Fireplace varaibale

Fireplace has NAs . Number of fireplace does not have any NAs.looks like NA is for the house with zero fireplaces

```{r}
table(all$FireplaceQu,all$Fireplaces,exclude=NULL)
all=all %>% replace_na(list(FireplaceQu="None"))
all$FireplaceQu=as.integer(recode(all$FireplaceQu,'None'=0,'Po'=1,'Fa'=2,'TA'=3,'Gd'=4,'Ex'=5))
table(all$FireplaceQu)
```

### Lot variables
LotFrontage : 486 NAs.  reasonable is impute meadian value per neighborhood

```{r}
all %>% drop_na(LotFrontage,SalePrice) %>% ggplot(aes(x=as.factor(Neighborhood),y=SalePrice))+geom_bar(stat="summary",fun.y="median",fill="blue") + theme(axis.text.x = element_text(angle=45,hjust=1))

all=all %>% group_by(Neighborhood) %>% mutate(LotFrontage=ifelse(is.na(LotFrontage),median(LotFrontage,na.rm=T),LotFrontage)) %>% 
  ungroup()
```

LotShape :No NAs , values seems ordinal
   Reg  Regular 
   IR1  Slightly irregular
   IR2  Moderately Irregular
   IR3  Irregular

```{r}
all$LotShape=as.integer(recode(all$LotShape,'IR3'=0,'IR2'=1,'IR1'=2,'Reg'=3))
```

LotConfig : No NAs. The value seems ordinal but visualizing it tells that it may not be ordinal. hence making it factor
```{r}
all %>% drop_na(LotFrontage,SalePrice) %>%ggplot(aes(x=as.factor(LotConfig),y=SalePrice))+geom_bar(stat="summary",fun.y="median",fill="blue") +theme(axis.text.x = element_text(angle=45,hjust=1))

all$LotConfig=as.factor(all$LotConfig)

table(all$LotConfig,exclude=NULL)
```

### Garage Variables
There are 7 Garage varaiables ,
```{r}
garage_variables=grep("Garage*",colnames(all),value = TRUE)
colSums(is.na(all[,garage_variables]))
```


For GarageYrBlt i am going to replace with YearBuilt variable

```{r}
all$GarageYrBlt[is.na(all$GarageYrBlt)]=all$YearBuilt[is.na(all$GarageYrBlt)]
```


lets check 157/159 missing values are the same observations . looks missing values are from the same observation

```{r}
length(which(is.na(all$GarageType) & is.na(all$GarageFinish) & is.na(all$GarageQual) & is.na(all$GarageCond)))
```


lets explore the two observations where GarageType has values. Observation 2127 does have seem have garage so lets imoute with common values
```{r}
all[which(!is.na(all$GarageType) & is.na(all$GarageFinish)),garage_variables]
which(!is.na(all$GarageType) & is.na(all$GarageFinish))


all$GarageCond[2127]=names(sort(table(all$GarageCond),decreasing = TRUE)[1])
all$GarageQual[2127]=names(sort(table(all$GarageQual),decreasing = TRUE)[1])
all$GarageFinish[2127]=names(sort(table(all$GarageFinish),decreasing = TRUE)[1])
```


Looks like this house does not have garage, hence making the garage varibale reflect it

```{r}
all[2577,garage_variables]

all[2577,'GarageType']=NA
all[2577,'GarageArea']=0
all[2577,'GarageCars']=0
```

Below 4 varaibale has 158 NA
```{r}
colSums(is.na(all[,garage_variables]))
```

First looking at GarageType , below value does not seems ordinal. replcae NA with 'No Garage' and converting as factor

```{r}
table(all$GarageType,exclude=NULL)
all=all %>% replace_na(list(GarageType="No Garage"))
all$GarageType=as.factor(all$GarageType)
```

Second, GarageFinish looks like ordinal value.

 Fin  Finished
 RFn  Rough Finished  
 Unf  Unfinished
 NA   No Garage
 
 
```{r}
all=all %>% replace_na(list(GarageFinish='None'))
all$GarageFinish=as.integer(recode(all$GarageFinish,'None'=0,'Unf'=1,'RFn'=2,'Fin'=3))
table(all$GarageFinish,exclude = NULL)
```

third , GarageQual

It is another ordinal value
   Ex   Excellent
   Gd   Good
   TA   Typical/Average
   Fa   Fair
   Po   Poor
   NA   No Garage
   
   
```{r}
all=all %>% replace_na(list(GarageQual='None'))
all$GarageQual=as.integer(recode(all$GarageQual,'None'=0,'Po'=1,'Fa'=2,'TA'=3,'Gd'=4,'Ex'=5))
table(all$GarageQual,exclude = NULL)
```


last GarageCondition , another ordinal variable

```{r}
all=all %>% replace_na(list(GarageCond='None'))
all$GarageCond=as.integer(recode(all$GarageCond,'None'=0,'Po'=1,'Fa'=2,'TA'=3,'Gd'=4,'Ex'=5))
table(all$GarageCond,exclude = NULL)
```


### Basement variables

There are 11 basement features , 5 of those have 79 - 82 missing values . and remaining has 1 or 2 missing values.

```{r}
bsmt_features=grep("Bsmt*",colnames(all),value = TRUE)
bsmt_features

colSums(is.na(all[,bsmt_features]))
```

check if how manu missing values are from same observation
```{r}
length(which(is.na(all$BsmtQual) & is.na(all$BsmtCond) & is.na(all$BsmtExposure) & is.na(all$BsmtFinType2)))
```

Find the other NAs, BsmtFinType1 has 79 missing value.

```{r}
all %>% filter(!is.na(BsmtFinType1) & (is.na(BsmtQual) | is.na(BsmtCond) | is.na(BsmtExposure)  | is.na(BsmtFinType2))) %>%  select(row_name,BsmtQual,BsmtCond,BsmtExposure,BsmtFinType1,BsmtFinType2)
```

lets impute with most comman value

```{r}
table(all$BsmtQual,exclude = NULL)
all[c(2218, 2219),"BsmtQual"]='TA'


table(all$BsmtExposure,exclude = NULL)
all[c(949, 1488, 2349),"BsmtExposure"]='No'


table(all$BsmtFinType2,exclude = NULL)
all[333,"BsmtFinType2"]='Unf'

table(all$BsmtCond,exclude = NULL)
all[c(2041, 2186, 2525),"BsmtCond"]='TA'
```


BsmtQual 
This can be made as ordinal , replace NA with 'None'
```{r}
all=all %>% replace_na(list(BsmtQual='None'))
table(all$BsmtQual,exclude = NULL)

all$BsmtQual=as.integer(recode(all$BsmtQual,'None'=0,'Po'=1,'Fa'=2,'TA'=3,'Gd'=4,'Ex'=5))

table(all$BsmtQual,exclude = NULL)
```

BsmtCond
This can be made ordinal, replace NA with 'None'

```{r}
table(all$BsmtCond,exclude = NULL)
all=all %>% replace_na(list(BsmtCond='None'))
table(all$BsmtCond,exclude = NULL)

all$BsmtCond=as.integer(recode(all$BsmtCond,'None'=0,'Po'=1,'Fa'=2,'TA'=3,'Gd'=4,'Ex'=5))

table(all$BsmtCond,exclude = NULL)
```



BsmtExposure
This can be made ordinal, replace NA with 'None'

```{r}
table(all$BsmtExposure,exclude = NULL)
all=all %>% replace_na(list(BsmtExposure='None'))
table(all$BsmtExposure,exclude = NULL)

all$BsmtExposure=as.integer(recode(all$BsmtExposure,'None'=0, 'No'=1, 'Mn'=2, 'Av'=3, 'Gd'=4))

table(all$BsmtExposure,exclude = NULL)
```

BsmtFinType1
This variable can be made ordinal

   GLQ  Good Living Quarters
   ALQ  Average Living Quarters
   BLQ  Below Average Living Quarters   
   Rec  Average Rec Room
   LwQ  Low Quality
   Unf  Unfinshed
   NA   No Basement
   
```{r}
all=all %>% replace_na(list(BsmtFinType1='None'))
all$BsmtFinType1=as.integer(recode(all$BsmtFinType1,'None'=0, 'Unf'=1, 'LwQ'=2, 'Rec'=3, 'BLQ'=4, 'ALQ'=5, 'GLQ'=6))


```



BsmtFinType2
This variable can be made ordinal

```{r}
table(all$BsmtFinType2,exclude = NULL)
all=all %>% replace_na(list(BsmtFinType2='None'))

all$BsmtFinType2=as.integer(recode(all$BsmtFinType2,'None'=0, 'Unf'=1, 'LwQ'=2, 'Rec'=3, 'BLQ'=4, 'ALQ'=5, 'GLQ'=6))

table(all$BsmtFinType2,exclude = NULL)
```


Still 6 bsmt variable with 1 or 2 missing values
```{r}
colSums(is.na(all[,bsmt_features]))
```


```{r}
all[is.na(all$BsmtFinSF1) | is.na(all$BsmtFinSF2) | is.na(all$BsmtUnfSF) | is.na(all$TotalBsmtSF) | is.na(all$BsmtFullBath) | is.na(all$BsmtHalfBath),c('row_name',bsmt_features)]
```

remaining 79 observations does not have basement , hence lets fix these 2 observation 

BsmtFullBath - Replace nulls with zero
```{r}
table(all$BsmtFullBath,exclude = NULL)
all=all %>% replace_na(list(BsmtFullBath=0))
```

BsmtHalfBath - Replace nulls with zero
```{r}
table(all$BsmtHalfBath,exclude = NULL)
all=all %>% replace_na(list(BsmtHalfBath=0))
```

BsmtFinSF1 - Replace nulls with zero
```{r}
table(all$BsmtFinSF1,exclude = NULL)
all=all %>% replace_na(list(BsmtFinSF1=0))
```



BsmtFinSF2 - Replace nulls with zero
```{r}
table(all$BsmtFinSF2,exclude = NULL)
all=all %>% replace_na(list(BsmtFinSF2=0))
```



BsmtUnfSF - Replace nulls with zero
```{r}
table(all$BsmtUnfSF,exclude = NULL)
all=all %>% replace_na(list(BsmtUnfSF=0))
```



TotalBsmtSF - Replace nulls with zero
```{r}
table(all$TotalBsmtSF,exclude = NULL)
all=all %>% replace_na(list(TotalBsmtSF=0))
```




### Masonary Variables

Two variables MasVnrType & MasVnrArea . MasVnrType has 24 missing and MasVnrArea has 23 missing
```{r}
MasV_variables=grep("MasV*",colnames(all),value = TRUE)
colSums(is.na(all[MasV_variables]))
```

check if the missing values from both the observation are same and.... it looks like ther are the same observation

```{r}
sum(is.na(all$MasVnrArea) & is.na(all$MasVnrType))
```

find the observation with 1 extra missing MasvnrArea , Lets replace the missing value with 'BrkFace'
```{r}
all[which(!is.na(all$MasVnrArea) & is.na(all$MasVnrType)),c("MasVnrArea","MasVnrType")]
all %>% group_by(MasVnrType) %>% summarise(median_Area=median(MasVnrArea),cnt=n())
which(!is.na(all$MasVnrArea) & is.na(all$MasVnrType))
all[2611,'MasVnrType']='BrkFace'
```

Replace the NA with 'None' in MasVnrType
```{r}
all=all %>% replace_na(list(MasVnrType='None'))
```


Looks like common brick and None are cheaper than other categories , will make the variable ordinal accordingly

```{r}
all %>% drop_na(SalePrice) %>% group_by(MasVnrType) %>% summarise(median=median(SalePrice),cnt=n()) %>% arrange(median)


all$MasVnrType=as.integer(recode(all$MasVnrType,'BrkCmn'=0,'None'=0,'BrkFace'=1,'Stone'=2))

table(all$MasVnrType,exclude =NULL)
```

Replace NULL with zeros in MasVnrArea column
```{r}
all=all %>% replace_na(list(MasVnrArea=0))
summary(all$MasVnrArea)
```


### MSZoning 

It has 4 NAs . Values are categorical.

   A    Agriculture
   C    Commercial
   FV   Floating Village Residential
   I    Industrial
   RH   Residential High Density
   RL   Residential Low Density
   RP   Residential Low Density Park 
   RM   Residential Medium Density
   
Lets impute with most common value and convert into factor   
```{r}
table(all$MSZoning,exclude = NULL)

all$MSZoning[is.na(all$MSZoning)]=names(sort(table(all$MSZoning),decreasing = TRUE)[1])

table(all$MSZoning,exclude = NULL)

all$MSZoning=as.factor(all$MSZoning)
```

### Kitchen Variables

KitchenQual : Kitchen quality
It has just one missing variable

```{r}
table(all$KitchenQual,exclude = NULL)
```

replace that variable with most common value
```{r}
which(is.na(all$KitchenQual))
all[1556,"KitchenQual"]="TA"
all$KitchenQual=as.integer(recode(all$KitchenQual,'None'=0,'Po'=1,'Fa'=2,'TA'=3,'Gd'=4,'Ex'=5))

table(all$KitchenQual,exclude = NULL)
```

Number of kitchens above grade
No missing values
```{r}
table(all$KitchenAbvGr)
```


### Utilities
All houses has all public utilities except one and 'NoSeWa' is in train . Hence this variable is useless . hence removing this variable .

```{r}
table(all$Utilities,exclude = NULL)

all$Utilities=NULL
```

### Home Functionality
Ordinal values (Salvage is worst and Typical is best)

   Typ  Typical Functionality
   Min1 Minor Deductions 1
   Min2 Minor Deductions 2
   Mod  Moderate Deductions
   Maj1 Major Deductions 1
   Maj2 Major Deductions 2
   Sev  Severely Damaged
   Sal  Salvage only
Replace the null values with mode
```{r}
table(all$Functional,exclude=NULL)
all=all %>% replace_na(list(Functional="Typ"))

all$Functional=as.integer(recode(all$Functional,'Sal'=0,'Sev'=1,'Maj2'=2,'Maj1'=3,'Mod'=4,'Min2'=5,'Min1'=6,'Typ'=7))

```


### Exterior Variable

There are 4 Exterior variable. Exterior1st & Exterior2nd has one missing value each
```{r}
exterior_variable=grep("Exter*",colnames(all),value=T)
exterior_variable
colSums(is.na(all[,exterior_variable]))
```

Exterior1st - Impute with mode and convert as factor
```{r}
table(all$Exterior1st,exclude = NULL)
which(is.na(all$Exterior1st))
all[2152,"Exterior1st"]="VinylSd"

all$Exterior1st=as.factor(all$Exterior1st)
```

Exterior2nd - Impute with mode and convert as factor

```{r}
table(all$Exterior2nd,exclude = NULL)
which(is.na(all$Exterior2nd))
all[2152,"Exterior2nd"]="VinylSd"
all$Exterior2nd=as.factor(all$Exterior2nd)
```

ExterQual
Nominal values - lets convert to Nominal

```{r}
table(all$ExterQual,exclude = NULL)

all$ExterQual=as.integer(recode(all$ExterQual,'None'=0,'Po'=1,'Fa'=2,'TA'=3,'Gd'=4,'Ex'=5))
```


ExterCond
No Na. can be converted to Ordinal.

```{r}
table(all$ExterCond,exclude = NULL)
all$ExterCond=as.integer(recode(all$ExterCond,'None'=0,'Po'=1,'Fa'=2,'TA'=3,'Gd'=4,'Ex'=5))
```


### Electrical system

It is categorical feature. replace na with most common value and convert to factor
```{r}
table(all$Electrical,exclude = NULL)
which(is.na(all$Electrical))
all[1380,"Electrical"]="SBrkr"
all$Electrical=as.factor(all$Electrical)
```


### SaleType and Condition

SaleType
Values are categorical, replace na with most common value and convert as factor

```{r}
table(all$SaleType,exclude = NULL)
which(is.na(all$SaleType))
all[2490,"SaleType"]="WD"
all$SaleType=as.factor(all$SaleType)
```

Condtion of sale

categorical value

```{r}
table(all$SaleCondition,exclude = NULL)

all$SaleCondition=as.factor(all$SaleCondition)
```



Character Variables

There are 15 char features.

```{r}
char_features=all %>% select_if(is.character) %>% colnames(.)
char_features
```

## {.tabset}

### Foundation 

Lets replace this as factor variable

    BrkTil          Brick & Tile
    CBlock          Cinder Block
    PConc           Poured Contrete 
    Slab            Slab
    Stone           Stone
    Wood            Wood
```{r}
table(all$Foundation)
all$Foundation=as.factor(all$Foundation)
```

### Heating and Air conditioning


Heating , convert into factor
```{r}
table(all$Heating)
all$Heating=as.factor(all$Heating)
```

HeatingQC , looks like ordinal value . can be converted to ordinal
```{r}
table(all$HeatingQC)
all$HeatingQC=as.integer(recode(all$HeatingQC,'None'=0,'Po'=1,'Fa'=2,'TA'=3,'Gd'=4,'Ex'=5))

```

CentralAir - Can be converted into nominal value

```{r}
table(all$CentralAir)
all$CentralAir=as.integer(recode(all$CentralAir,'N'=0,'Y'=1))
```


### Roof

RoofStyle - convert to factor

```{r}
table(all$RoofStyle)
all$RoofStyle=as.factor(all$RoofStyle)
```


RoofMatl - convert to factor

```{r}
table(all$RoofMatl)
all$RoofMatl=as.factor(all$RoofMatl)
```


### Land

LandContour - convert to factors

```{r}
table(all$LandContour)

all$LandContour=as.factor(all$LandContour)
```


LandSlope - convert to factors
```{r}
table(all$LandSlope)

all$LandSlope=as.integer(recode(all$LandSlope,'Sev'=0, 'Mod'=1, 'Gtl'=2))
```


### Building Type

BldgType - convert as factors

```{r}
table(all$BldgType)
all$BldgType=as.factor(all$BldgType)
```


HouseStyle - convert to factor

```{r}
table(all$HouseStyle)
all$HouseStyle=as.factor(all$HouseStyle)
```


### Neighborhood 

Neighboorhood - convert to factors

```{r}
table(all$Neighborhood)
all$Neighborhood=as.factor(all$Neighborhood)
```


Condition1 & condition2- convert to factor

```{r}
table(all$Condition1)
all$Condition1=as.factor(all$Condition1)

table(all$Condition2)
all$Condition2=as.factor(all$Condition2)
```


### Street & Driveaway

Street - Ordinal 
```{r}
table(all$Street)

all$Street=as.integer(recode(all$Street,"Grvl"=0,"Pave"=1))
```

PavedDrive - convert to ordinal

   Y    Paved 
   P    Partial Pavement
   N    Dirt/Gravel

```{r}
table(all$PavedDrive)

all$PavedDrive=as.integer(recode(all$PavedDrive,'N'=0,'P'=1,'Y'=2))
```


Changing numerical variable to factors

At this point , all the missing values are imputed and char features are converterd as either numeric or factors

Year and Month sold

since House sold in december does not fetch high value than the houses sold in January . Converting Monthsold a s factor


```{r}
table(all$MoSold)
all$MoSold=as.factor(all$MoSold)
```


Median prices by year and by month. we can see median hous price decreasing after 2007 due to financial crisis. Also seasonility seems to play big role.

```{r}
yr_plot=all %>% drop_na(SalePrice) %>% ggplot(aes(x=YrSold,y=SalePrice)) + geom_bar(stat="summary",fun.y="median",fill="blue")+scale_y_continuous(breaks=seq(0,800000,by=25000),label = comma)+coord_cartesian(ylim=c(0,200000))+geom_hline(yintercept =163000,linetype="dashed",color="red")

mo_plot=all %>% drop_na(SalePrice) %>% ggplot(aes(x=MoSold,y=SalePrice)) + geom_bar(stat="summary",fun.y="median",fill="blue")+scale_y_continuous(breaks=seq(0,800000,by=25000),label = comma)+coord_cartesian(ylim=c(0,200000))+geom_hline(yintercept =163000,linetype="dashed",color="red")


grid.arrange(yr_plot,mo_plot,widths=c(1,2))
```


### MSSubClass

it is the numerical value but should be encoded as categories.

```{r}
table(all$MSSubClass)

all$MSSubClass=as.factor(all$MSSubClass)

all$MSSubClass=recode(all$MSSubClass,'20'='1 story 1946+', '30'='1 story 1945-', '40'='1 story unf attic', '45'='1,5 story unf', '50'='1,5 story fin', '60'='2 story 1946+', '70'='2 story 1945-', '75'='2,5 story all ages', '80'='split/multi level', '85'='split foyer', '90'='duplex all style/age', '120'='1 story PUD 1946+', '150'='1,5 story PUD all', '160'='2 story PUD 1946+', '180'='PUD multilevel', '190'='2 family conversion')


table(all$MSSubClass)
```



Correlations

```{r}
numeric_feature=which(sapply(all,is.numeric))

numeric_feature

factor_feature=which(sapply(all,is.factor))
factor_feature

all_num_feature=all[,numeric_feature]

# Finding correlation of all numric features
cor_numVar=cor(all_num_feature,use="pairwise.complete.obs")

#Sort on decreasing correlation with SalePrice
cor_sorted=as.matrix(sort(cor_numVar[,"SalePrice"],decreasing = T))

#select only the correlation above 0.5
high_cor_num_features=names(which(apply(cor_sorted,1,function (x) abs(x)>0.5)))

cor_numVar=cor_numVar[high_cor_num_features,high_cor_num_features]

corrplot.mixed(cor_numVar,tl.pos="lt",tl.col="black",tl.cex = 0.7,cl.cex = .7, number.cex=.7)
```



Remove row_name 

```{r}
all$row_name=NULL
```


As you can see number of variables with high (0.5) correlation increased to 16 from 10.



Finding the variable importance using RandomForest

```{r}
set.seed(2018)
quickRF=all %>% drop_na(SalePrice) %>% randomForest::randomForest(SalePrice~.,ntree=100,importance=T,data=.)

imp_RF=importance(quickRF)
imp_DF=data.frame(variables=row.names(imp_RF),MSE=imp_RF[,1])
imp_DF=imp_DF %>% arrange(desc(MSE))


imp_DF[1:20,] %>% ggplot(aes(x=reorder(variables,MSE),y=MSE,fill=MSE))+geom_bar(stat="identity")+coord_flip()
```


Lets take a look at it square feet varaibale. looks like GrLivArea is sum of 1stFlrSf , 2ndFlrSF & LowQualFinSf

```{r}
all %>% select(GrLivArea,X1stFlrSF,X2ndFlrSF,LowQualFinSF)

cor(all$GrLivArea,(all$X1stFlrSF+all$X2ndFlrSF+all$LowQualFinSF))
```


Lets explore the neighbourhood varaiable

```{r}
n1=all %>% drop_na(SalePrice) %>% ggplot(aes(x=Neighborhood,y=SalePrice))+
  geom_bar(stat="summary",fun.y='median',fill='blue')+
  scale_y_continuous(breaks = seq(0,800000,by=50000),labels = comma) +
  theme(axis.text.x=element_text(angle=45,hjust=1)) +
  geom_hline(yintercept = 163000,linetype="dashed",color="red") +
  geom_label(stat="count",aes(label=..count..,y=..count..),size=3)


n2=all %>% ggplot(aes(x=Neighborhood))+geom_histogram(stat="count")+theme(axis.text.x = element_text(angle = 45))+geom_label(stat="count",aes(label=..count..,y=..count..))


grid.arrange(n1,n2)
```


Overall Quality, and other quality variables

```{r}
q1=all %>% ggplot(aes(x=as.factor(OverallQual))) +
  geom_histogram(stat="count")

q2=all %>% ggplot(aes(x=as.factor(ExterQual))) +
  geom_histogram(stat="count")

q3=all %>% ggplot(aes(x=as.factor(BsmtQual))) +
  geom_histogram(stat="count")

q4=all %>% ggplot(aes(x=as.factor(KitchenQual))) +
  geom_histogram(stat="count")

q5=all %>% ggplot(aes(x=as.factor(GarageQual))) +
  geom_histogram(stat="count")

q6=all %>% ggplot(aes(x=as.factor(FireplaceQu))) +
  geom_histogram(stat="count")

q7=all %>% ggplot(aes(x=as.factor(PoolQC))) +
  geom_histogram(stat="count")

grid.arrange(q1,q2,q3,q4,q5,q6,q7)

```

PoolQC is very sparse

The second most important categorical: MSSubClass

```{r}
ms1=all %>% drop_na(SalePrice) %>% ggplot(aes(x=MSSubClass,y=SalePrice))+
  geom_bar(stat="summary",fun.y='median',fill='blue')+
  scale_y_continuous(breaks = seq(0,800000,by=50000),labels = comma) +
  theme(axis.text.x=element_text(angle=45,hjust=1)) +
  geom_hline(yintercept = 163000,linetype="dashed",color="red") +
  geom_label(stat="count",aes(label=..count..,y=..count..),size=3)


ms2=all %>% ggplot(aes(x=MSSubClass))+geom_histogram(stat="count")+theme(axis.text.x = element_text(angle = 45))+geom_label(stat="count",aes(label=..count..,y=..count..))


grid.arrange(ms1,ms2)
```

Garage variables

```{r}
g1=all %>% ggplot(aes(x=as.factor(GarageCars)))+
  geom_histogram(stat="count")

g2=all %>% ggplot(aes(x=GarageYrBlt))+
  geom_histogram()

g3=all %>% ggplot(aes(x=GarageArea))+
  geom_density()

g4=all %>% ggplot(aes(x=as.factor(GarageCond)))+
  geom_histogram(stat="count")


g5=all %>% ggplot(aes(x=as.factor(GarageType)))+
  geom_histogram(stat="count")


g6=all %>% ggplot(aes(x=as.factor(GarageQual)))+
  geom_histogram(stat="count")


g7=all %>% ggplot(aes(x=as.factor(GarageFinish)))+
  geom_histogram(stat="count")

grid.arrange(g1,g2,g3,g4,g5,g6,g7)
```


Lets fix the typo "2207" in the garageyrblt
```{r}
summary(all$GarageYrBlt)



all$GarageYrBlt[all$GarageYrBlt==2207]=2007
```



Feature Engineering

1. Bathroom
There are 4 varaiables . Going to create a new varaiable total bathroom .

Now total bathroom has positivly correlated with saleprice (actually 0.63! )
```{r}
bathroom_variables=grep("*Bath*",colnames(all),value=T)

all=all %>% 
  mutate(TotalBathrooms=BsmtFullBath+BsmtHalfBath*.5+FullBath+HalfBath*.5)


p1=all %>% drop_na(SalePrice) %>% 
  ggplot(aes(x=as.factor(TotalBathrooms),y=SalePrice))+
  geom_point(col='blue')+
  geom_smooth(method = 'lm',color='black',se=FALSE,aes(group=1))

p2=all %>% ggplot(aes(x=as.factor(TotalBathrooms))) +
  geom_histogram(stat="count")

grid.arrange(p1,p2)

cor(all[!is.na(all$SalePrice),'TotalBathrooms'],all[!is.na(all$SalePrice),'SalePrice'])
```

Adding House age

There are 3 year variable in the dataset , YrBulit,YearRemodAdd and YearSold . YearRemodAdd defaults to YrBuilt if no remodeling is done . So Age feature is derived from YearSold - YearRemodAdd. Also ia m going to add feature Remodeled (Yes/ No) feature to indicat ethis house was remodeled.

as you see in the below chart , Age is negetively correlated with SalePrice.

```{r}
all$Age=all$YrSold-all$YearRemodAdd

all$Remod=ifelse(all$YearRemodAdd>all$YearBuilt,1,0)

all %>% drop_na(SalePrice) %>% 
  ggplot(aes(x=Age,y=SalePrice))+geom_point(col='blue')+
  geom_smooth(method='lm')


cor(all[!is.na(all$SalePrice),'Age'],all[!is.na(all$SalePrice),'SalePrice'])
```


As you can see remodeled houses are lower price compared to non remodeled house.
```{r}
all %>% drop_na(SalePrice) %>% 
  ggplot(aes(x=Remod,y=SalePrice))+
  geom_bar(stat='summary',fun.y='median',fill='blue')+
  geom_hline(yintercept = 163000,linetype="dashed",col='red')
```


Finally i am creating the isNew feature , to indicate the house was built on the year when it was sold. As you can see new houses worth more than old houses

```{r}
all$isNew=ifelse(all$YearBuilt==all$YrSold,1,0)

all %>% drop_na(SalePrice) %>% 
  ggplot(aes(x=isNew,y=SalePrice))+
  geom_bar(stat='summary',fun.y='median',fill='blue')+
  geom_hline(yintercept = 163000,linetype="dashed",col='red')


all$YrSold=as.factor(all$YrSold)
```

Binning Neighboorhood



```{r}
p1=all %>% drop_na(SalePrice) %>% 
  ggplot(aes(x=reorder(Neighborhood,SalePrice),y=SalePrice))+
  geom_bar(stat="summary",fun.y='median',fill='blue')+
  theme(axis.text.x=element_text(angle=45,hjust=1))+labs(title="Median")


p2=all %>% drop_na(SalePrice) %>% 
  ggplot(aes(x=reorder(Neighborhood,SalePrice),y=SalePrice))+
  geom_bar(stat="summary",fun.y='mean',fill='blue')+
  theme(axis.text.x=element_text(angle=45,hjust=1))+labs(title="Mean")

grid.arrange(p1,p2)
```

Based on the chart above , going to create three groups

```{r}
all=all %>% mutate(NeighRich=ifelse(Neighborhood %in% c("StoneBr","NridgHt","NoRidge"),2,
                                ifelse(Neighborhood %in% c("MeadowV","IDOTRR","BrDale"),0,1)))
```

Total Squarefeet


creating the total square feet feature . As expected 
```{r}
all$TotalSqfeet=all$GrLivArea+all$TotalBsmtSF

all %>% drop_na(SalePrice) %>% 
  ggplot(aes(x=TotalSqfeet,y=SalePrice))+
  geom_point(col='blue')+
  geom_smooth(method='lm',se=FALSE,col='black')


cor(all[!is.na(all$SalePrice),"SalePrice"],all[!is.na(all$SalePrice),"TotalSqfeet"])
```

As expected TotalSqfeet is highly corrlated (0.77)


Consolidating the Porch variable, but correlation is not high (0.19)

```{r}
all$TotalPorchSF=all$OpenPorchSF+all$EnclosedPorch+all$X3SsnPorch+all$ScreenPorch


all %>% drop_na(SalePrice) %>% 
  ggplot(aes(x=TotalPorchSF,y=SalePrice))+
  geom_point(col='blue')+
  geom_smooth(method='lm',se=FALSE,col='black')


cor(all[!is.na(all$SalePrice),"SalePrice"],all[!is.na(all$SalePrice),"TotalPorchSF"])
```



Preparing data for modeling

Droping the highly correlated variables , for example Garage cars and Garage Area has higly correlated (0.89) between two i am going to drop GarageArea which has lower correlation with SalePrice.

```{r}
drop_var=c('YearRemodAdd','GarageArea','GarageYrBlt','TotRmsAbvGrd','TotalBsmtSF','ExterQual','GarageCond')

all=all %>% select(-one_of(drop_var))
```


Removing Outlier

For timebeing i am going to remove the two outlier house which are big but fetched low price.

```{r}
all = all[-c(524, 1299),]
```

Preprocessing predictor variable

```{r}
all_numVar=names(all_numVar)[!(names(all_numVar) %in% c('MSSubClass', 'MoSold', 'YrSold', 'SalePrice', 'OverallQual', 'OverallCond'))]

all_numVar=append(all_numVar,c('Age','TotalPorchSF','TotalBathrooms','TotalSqfeet'))


DF_Numeric=all[,names(all) %in% all_numVar]

DF_Factor=all[,!colnames(all) %in% all_numVar]
DF_Factor=DF_Factor[,colnames(DF_Factor) != 'SalePrice']

cat('There are ',length(DF_Numeric),' numeric variables and ',length(DF_Factor) ,' factor variables')
```


Skewness and normalizing the numeric predictors 

Skewness is a measure of the symmetry in a distribution. A symmetrical dataset will have a skewness of zero . Skewness measure the relative size of teh two tails. Skewness of +1 to -1 is considered to be fairly symmetrical.

Going to log transform the variables if the skewness is greater than 0.8.

```{r}
skewed_features=names(which(abs(sapply(DF_Numeric,skew))>0.8))

DF_Numeric=DF_Numeric %>%
   mutate_at(vars(skewed_features),funs(log(.+1)))
```


Normalizing the data.
```{r}
preNum=preProcess(DF_Numeric,method=c("center","scale"))
preNum


DFnorm=predict(preNum,DF_Numeric)
dim(DFnorm)
```


One hot encoding
The last step needed to ensure that all predictors are converted into numeric columns is to one-hot encode'

```{r}
DF_Dummies=as.data.frame(model.matrix(~.-1,DF_Factor))
dim(DF_Dummies)
```


Removing labels with few or no observations in train or test

```{r}
ZeroColTest=which(colSums(DF_Dummies[(nrow(all[!is.na(all$SalePrice),])+1):nrow(all),])==0)
  
colnames(DF_Dummies[ZeroColTest])
  
```


Removing predictors
```{r}
DFdummies=DF_Dummies[,-ZeroColTest]
```

Doing the same test for training test .

```{r}
ZeroColTrain=which(colSums(DF_Dummies[1:(nrow(all[!is.na(all$SalePrice),])),])==0)

ZeroColTrain
```

Removing the predictor

```{r}
DFdummies=DFdummies[,-ZeroColTrain]
```

Also taking out variables with less than 10 ones in the train set.

```{r}
fewOnes=which(colSums(DFdummies[1:(nrow(all[!is.na(all$SalePrice),])),])<10)

colnames(DFdummies[fewOnes])
```

Taking out the featueres with less than 10 'ones' in the train set.
```{r}
DFdummies=DFdummies[,-fewOnes]

dim(DFdummies)
```


Lets combine numeric and factor predictor
```{r}
combined=cbind(DFnorm,DFdummies)
```


Dealing with skewness of response variable

```{r}
skew(all$SalePrice)
```


```{r}
qqnorm(all$SalePrice)
qqline(all$SalePrice)
```

Skew of 1.87 indicates right skew ,and the Q-Q plot shows that saleprice is not normally distributed. So i am taking log transformation . Now skew is quite low

```{r}
all$SalePrice=log(all$SalePrice)
skew(all$SalePrice)

qqnorm(all$SalePrice)
qqline(all$SalePrice)
```

Composing train and test sets

```{r}
train1=combined[!is.na(all$SalePrice),]
test1=combined[is.na(all$SalePrice),]
```

Modeling

Lasso regression model

Below , i am using caret cross validation to tune lambda which is the only hyper parameter that needs to be tuned for the lasso model.

```{r}
set.seed(27042018)

my_control=trainControl(method = "cv",number=5)
lassoGrid=expand.grid(alpha=1,lambda=seq(0.001,0.1,by=0.005))

lasso_mod = train(x=train1, y=all$SalePrice[!is.na(all$SalePrice)],
                   method='glmnet',
                   trControl=my_control,
                   tuneGrid=lassoGrid)

lasso_mod$bestTune
```



```{r}
min(lasso_mod$results$RMSE)
```

```{r}
lassoVarImp=varImp(lasso_mod,scale=F)
lassoImportance=lassoVarImp$importance

varsSelected <- length(which(lassoImportance$Overall!=0))
varsNotSelected <- length(which(lassoImportance$Overall==0))

cat('Lasso uses', varsSelected, 'variables in its model, and did not select', varsNotSelected, 'variables.')
```


Prediction
```{r}
LassoPred=predict(lasso_mod,test1)
prediction_lasso=exp(LassoPred)
head(prediction_lasso)
```


XGBoost


```{r}
xgb_grid=expand.grid(nrounds=1000,
                     eta=c(.1,.05,.01),
                     max_depth=c(2,3,4,5,6),
                     gamma=0,
                     colsample_bytree=1,
                     min_child_weight=c(1,2,3,4,5),
                     subsample=1
)
```

Next step is to let the caret find the best hyperparameter values

```{r}
#xgb_caret <- train(x=train1, y=all$SalePrice[!is.na(all$SalePrice)], method='xgbTree', trControl= my_control, tuneGrid=xgb_grid)

#xgb_caret$bestTune
```

Below is teh tunned parameters

Max_depth=3
eta=0.05
Min_child_weight=4

```{r}
label_train=all$SalePrice[!is.na(all$SalePrice)]
```

create training & testing Dmatrix
```{r}
dtrain=xgb.DMatrix(data=as.matrix(train1),label=label_train)
dtest=xgb.DMatrix(data=as.matrix(test1))
```


creating xgboost parameters ,taking the tuned values from cross validation caret.

```{r}
default_param=list(objective="reg:linear",booster="gbtree",eta=0.05,gamma=0,max_depth=3,min_child_weight=4,subsample=1,colsample_bytree=1)
```

The next step is to cross validate to find the best number of rounds

```{r}
xgbcv=xgb.cv(params=default_param,data=dtrain,nrounds=500,nfold=5,showsd = T,stratified = T,print_every_n = 40,early_stopping_rounds = 10,maximize = F)
```


Trainign the model with best iteration found by cross validation

```{r}
xgb_mod=xgb.train(data=dtrain,params = default_param,nrounds=454)

XGBPred=predict(xgb_mod,dtest)

predictions_XGB=exp(XGBPred)

head(predictions_XGB)
```


Viewing variable importance plot.

```{r}
library(Ckmeans.1d.dp)


mat=xgb.importance(feature_names = colnames(train1),model=xgb_mod)
xgb.ggplot.importance(importance_matrix = mat[1:20],rel_to_first = TRUE)
```



